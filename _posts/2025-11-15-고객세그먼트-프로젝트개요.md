---
title: "[개인] RFM 기반 고객 세그먼트 분석 및 고객 이탈 분석을 통한 CRM 전략 수립 프로젝트  - 프로젝트개요"
excerpt: "대용량 로그데이터를 통해 고객 세그먼트 분석, 이탈 분석을 실시하고 대시보드로 설계하자"
date: 2025-11-15T12:00:00+09:00
last_modified_at: 2025-11-15T12:00:00+09:00
toc: true
toc_label: "목차"
toc_sticky: true
categories: [Project,RFM]
tags: [RFM, 고객 분석, 코호트 분석, Funnel, 이탈 분석, SparkSQL]
layout: single
---

## 프로젝트 개요
본 프로젝트는 **Kaggle E-commerce Behavior 데이터(약 4천만 건)**를 활용해  
고객의 구매 행동을 RFM 기반으로 세분화하고, **월별 고객 흐름(Transition)**을 분석하는 것을 목표로 합니다.

대규모 로그 데이터 특성에 맞추어 **Apache Spark + Delta Lake**로 대용량 전처리 및 월별 스냅샷을 생성하였고, 
세부적인 지표 산출 및 세그먼트 분석은 **PostgreSQL**를 통해 수행했습니다.
최종 분석 결과는 **Tableau 대시보드**로 시각화하여  
VIP·우수·성장·이탈 위험 고객의 분포, 변화, 매출 기여도를 직관적으로 확인할 수 있도록 구현했습니다.

---

## 1. 프로젝트 목표
고객 행동 데이터를 기반으로 RFM 세그먼트를 분류하고,  
월별 변화(전환·성장·이탈)를 추적하여 세그먼트별 핵심 행동 지표와 매출 변화를 분석한다.

---

## 2. 데이터 구성
- **출처:** Kaggle – *E-commerce Behavior Data*
- **기간:** 2019-10 ~ 2020-04
- **규모:** 약 4천만 rows (총 20GB - 압축파일 기준)
- **주요 컬럼:**  
  `event_time`, `event_type`, `product_id`, `category_id`,  
  `category_code`, `price`, `user_id`, `user_session`

---

## 3. 프로젝트 진행 과정

### 1) 데이터 로드 및 전처리 (Apache Spark)
- 7개월치 대규모 gzip 로그를 Spark로 병렬 처리  
- Delta Lake 포맷으로 변환해 고속 로딩 및 안정적 데이터 핸들링 확보  
- RFM 분석에 필요한 기준 정의 및 Snapshot용 데이터 구조 설계

---

### 2) RFM 스코어링 & 월별 스냅샷 생성
- **Recency (R):** 해당 월 스냅샷 기준 누적 마지막 구매일  
- **Frequency (F):** 당월 구매 횟수  
- **Monetary (M):** 당월 구매 금액  
- 각 월마다 **독립적으로 세그먼트 재분류** → 고객의 성장, 유지, 이탈 패턴을 동적으로 추적 가능


> #### 세그먼트 유형 (예시)
> 세그먼트는 **NTILE 기반 상대적 분류**를 활용했으며, 이탈 분석에서는 **별도의 절대 기준**을 적용하여 정확한 이탈 고객 구분을 수행했습니다.
> - **VIP 고객**
> - **우수 고객**
> - **성장 고객**
> - **일반 고객**
> - **이탈 예정 고객**
> - **이탈 고위험 고객**

---

### 3) 세그먼트 분석 (Spark SQL + PostgreSQL)
- 월별 고객 세그먼트 테이블 생성  
- **Transition Matrix** 구축 (예: 일반 → 성장 → 우수 → VIP)  
- 세그먼트별 매출 기여도 및 ARPU 분석  
- R/F/M 정규화 지표 산출  
- 고객 유지율을 파악하기 위한 **코호트 분석** 수행  
- 이탈 전후 행동 변화 분석  
- 이탈로 인한 **매출 감소액(손익)** 추정

---

### 4) Tableau 대시보드 시각화
- 월별 세그먼트 분포 시각화  
- **Transition Flow**를 통한 고객 이동 경로 파악  
- 세그먼트별 KPI(ARPU, 구매 횟수, 이탈률 등)  
- 이탈 위험 고객 모니터링  
- 세그먼트별 R/F/M 특성 비교  
- 탭 구성으로 **웹사이트형 UX**를 적용한 대시보드 디자인

---

## 4. 사용 기술 스택

| 구분 | 기술 |
|------|------|
| **데이터 처리** | Apache Spark, Delta Lake, PySpark |
| **데이터베이스** | PostgreSQL |
| **언어** | Python, SQL |
| **라이브러리** | pandas, pyspark.sql, numpy |
| **시각화** | Tableau |
| **분석 기법** | RFM Analysis, Cohort Analysis, Segment Transition, Uplift 분석 |

---

## 5. 진행 기간
총 **3주**  
  - 데이터 처리 및 스냅샷 생성: 0.5주  
  - RFM 스코어링 및 분석: 1.5주  
  - Tableau 대시보드 제작: 1주  

---

## 6. 기여도  
**100%** 
기획 → Spark → SQL → 분석 → 시각화 **전 과정 단독 수행**

---